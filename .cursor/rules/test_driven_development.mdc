---
description: 
globs: 
alwaysApply: false
---
---
name: test_driven_development
description: Standards for Test-Driven Development in the Social Script project
version: 1.0.0
author: Dan
# Test-Driven Development (TDD) Rule

<rule>
name: test_driven_development
description: Rules and standards for Test-Driven Development
filters:
  - type: file_extension
    pattern: "\\.(rb|rake)$"
  - type: directory
    pattern: "(test|app/services)"
  - type: content
    pattern: "Minitest::Test|class.*< Minitest::Test"
actions:
  - type: suggest
    message: |
      Test-Driven Development Rules:

      1. Test First, Code Second:
         - SEMPRE verifique se já existem testes
         - Crie testes ANTES da implementação
         - Use testes como documentação

      2. Processo de Implementação:
         a) Revise/Crie Testes
         b) Rode os testes (devem falhar)
         c) Implemente o código
         d) Rode os testes (devem passar)
         e) Refatore

      3. Estrutura dos Testes:
         ```ruby
         class ServiceNameTest < Minitest::Test
           def test_funcionalidade
             # verifica funcionalidade
           end

           def test_casos_limite
             # verifica casos de borda
           end
         end
         ```

      4. Validação de Passos:
         - Verifique localização dos testes
         - Revise testes existentes
         - Crie testes faltantes
         - Siga requisitos dos testes

      5. Error Prevention:
         - Não implemente sem testes
         - Não pule casos de borda
         - Não deixe testes falhando
         - Não faça apenas testes manuais
examples:
  - input: |
      # Ruim: Implementação sem testes
      class MyService
        def call
          # Código sem testes
        end
      end

      # Bom: Teste primeiro
      class MyServiceTest < Minitest::Test
        def test_call
          assert_equal :esperado, MyService.new.call
        end
      end
metadata:
  priority: high
  version: 1.0.0
  changelog:
    - version: 1.0.0
      changes:
        - Initial version
        - Added core TDD principles
        - Added spec structure examples
        - Added validation steps
</rule>

## Implementation Guide

1. **Encontrando Testes Existentes**
   ```bash
   find test/ -name "*_test.rb" | grep $FEATURE_NAME
   ```

2. **Criando Novos Testes**
   ```ruby
   # test/services/my_service_test.rb
   class MyServiceTest < Minitest::Test
     def test_call
       assert_equal :esperado, MyService.new.call
     end
   end
   ```

3. **Executando Testes**
   ```bash
   bin/rails test test/services/my_service_test.rb
   ```

4. **Implementação**
   ```ruby
   # app/services/my_service.rb
   class MyService
     def call
       # Implementation following test requirements
     end
   end
   ```

## Best Practices

1. **Organização dos Testes**
   - Um arquivo de teste por classe/módulo
   - Agrupamento lógico de métodos de teste
   - Nomes de teste claros e descritivos

2. **Test Coverage**
   - Happy path scenarios
   - Edge cases
   - Error conditions
   - Boundary values

3. **Manutenibilidade**
   - DRY usando métodos auxiliares
   - Setup claro usando setup/before
   - Testes isolados
   - Asserções significativas

4. **Documentação**
   - Testes servem como documentação
   - Descrições claras
   - Exemplos de uso
   - Documentação de casos de borda

## Overview

This rule establishes Test-Driven Development (TDD) as the standard approach for implementing services and complex code in the Social project.

## Core Principles

1. **Test First, Code Second**
   - SEMPRE verifique se já existem testes before modifying or creating code
   - If no test exists, create one BEFORE implementing the feature
   - Use tests to define the expected behavior and interface

2. **Estrutura dos Testes**
   ```ruby
   class ServiceNameTest < Minitest::Test
     def test_funcionalidade
       # verifica funcionalidade principal
     end

     def test_casos_limite
       # verifica casos de borda
     end
   end
   ```

3. **Processo de Implementação**
   a. Review existing tests (if any)
   b. Write new tests defining expected behavior
   c. Run tests (they should fail)
   d. Implement code to make tests pass
   e. Refactor while keeping tests green

## Example from TranscriptFetcher

Good:
```ruby
# First: Review transcript_parser_test.rb
class TranscriptParserParserTest < Minitest::Test
  def test_retorna_transcript
    # verifica retorno
  end

  def test_segmentos_estruturados
    # verifica segmentos
  end
end

# Then: Implement service based on test
class TranscriptFetcherService
  def call
    # Implementation follows test requirements
  end
end
```

Bad:
```ruby
# Writing implementation first without tests
class TranscriptFetcherService
  def call
    # Implementation without clear requirements
    # No validation of behavior
    # No test coverage
  end
end
```

## Validation Steps

Before implementing any service or complex code:

1. **Verificação de Localização dos Testes**
   ```bash
   find test/ -name "*_test.rb" | grep $FEATURE_NAME
   ```

2. **Revisão dos Testes**
   - Read all related tests
   - Understand shared examples
   - Note edge cases
   - Review fixtures

3. **Criação de Testes (se necessário)**
   - Create test file
   - Write comprehensive tests
   - Write context-specific tests
   - Add edge case tests

4. **Implementação**
   - Follow test requirements
   - Run tests frequently
   - Keep tests green

## Common Patterns

1. **Service Tests**
   ```ruby
   class ServiceNameTest < Minitest::Test
     def test_funcionalidade
       # verifica funcionalidade principal
     end

     def test_casos_limite
       # verifica casos de borda
     end
   end
   ```

2. **Model Tests**
   ```ruby
   class ServiceNameTest < Minitest::Test
     def test_funcionalidade
       # verifica funcionalidade principal
     end

     def test_casos_limite
       # verifica casos de borda
     end
   end
   ```

## Error Prevention

1. Never start implementation without tests
2. Don't modify existing code without reviewing tests
3. Don't skip writing tests for edge cases
4. Don't leave failing tests unresolved

## Examples

### Good Process
1. Check for tests
2. Review existing tests
3. Write new tests
4. Implement feature
5. Refactor

### Bad Process
1. Start coding immediately
2. Test manually
3. Fix bugs as they appear
4. Write tests later (or never)

## References

- Full documentation in `docs/reference-docs/tdd.md`
- Minitest documentation
- Factory Bot documentation
- VCR documentation

## Enforcement

The AI assistant should:

1. ALWAYS check for existing tests first
2. Suggest creating tests if none exist
3. Follow test requirements
4. Reference relevant tests in responses
5. Keep tests green
6. Prevent implementation without tests

## Examples

### Finding Tests
```bash
# Good
find test/ -name "*transcript*_test.rb"

# Bad
Start implementing without checking
```

## Real-World Example: Transcript Parser Recovery

This example demonstrates how we recovered from an incorrect implementation approach by returning to TDD principles:

### Initial Mistake (What Not To Do)
```ruby
# BAD: Started with implementation without tests
class TranscriptParser
  def parse(content)
    # Started writing parser logic without clear requirements
    # No validation of expected output structure
    # Led to confusion about expected behavior
  end
end
```

### TDD Recovery Process

1. **Step 1: Stop and Write Tests First**
```ruby
# GOOD: Created comprehensive tests first
class TranscriptParserParserTest < Minitest::Test
  def test_retorna_transcript
    # verifica retorno
  end

  def test_segmentos_estruturados
    # verifica segmentos
  end
end
```

2. **Step 2: Implement Against Tests**
```ruby
class TranscriptParser
  def parse(content)
    format = detect_format(content)
    segments = parse_segments(content, format)
    
    Transcript.new(
      segments: segments,
      speakers: extract_speakers(segments)
    )
  end
  
  private
  
  def detect_format(content)
    # Implementation guided by format-specific tests
  end
  
  def parse_segments(content, format)
    # Implementation driven by segment structure tests
  end
  
  def extract_speakers(segments)
    # Implementation guided by speaker identification tests
  end
end
```

### Key Learnings

1. **Problem**: Starting with implementation led to:
   - Unclear requirements
   - Missing edge cases
   - No validation of output structure
   - Difficulty testing different formats

2. **Solution**: Returning to TDD principles:
   - Wrote comprehensive tests first
   - Defined clear expectations
   - Covered multiple formats
   - Validated output structure
   - Used shared examples for common behavior

3. **Benefits Realized**:
   - Clear interface definition
   - Confidence in format handling
   - Easy to add new formats
   - Maintainable test suite
   - Documented behavior

This real-world example demonstrates how returning to TDD principles helped recover from an implementation-first approach and led to a more robust, well-tested solution.